# Part 2: Generalization and Regularization
Generalization refers to the ability of the model to make accurate predictions on unseen data (also called `test set`). Although the test set and training set are typically of the same data distribution the model could perform overly good at the training set and perform poorly on the test set which is the refereed to as `overfitting` problem. Alternatively the model could perform poorly on both training and test set which refereed to as `underfitting` problem.

In order to select a model with high generalization, we need to find a balance between bias and variance in the the data. Underfitting or high `bias` occurs if the model is not complex enough to capture the underlying structure of the data. On the other hand, there is an opposite case where the model is too complex and it learns the noise and fluctuations in data making it perform too well on the training set but poorly on the test set. This case is where the model has high variance meaning that it is too sensitive to the training data and a minimal change to the data would change the fitting curve which effectively make the model not generalizable. `Note` that if the database is too large, a complex model is typically able to find the underlying pattern of data and ignore the `outliers`. The goal is to tune the model complexity using bias variance tradeoff to find a balance where both variance and bias is as low as possible.

### Double descent phenomenon
A complimentary principle to the bias variance tradeoff is the double descent phenomenon, which is specific to model complexity that is measured only by the number of parameters. It demonstrates that increasing the number of parameters in a model can lead to a second descent in the test error curve, where the error decreases again after initially increasing. This phenomenon challenges the conventional belief that there is approximately a U shaped test error as a result of bias variance, when model complexity gradually increases. It is also demonstrated that the observed peaks of the test error in the double descent phenomenon can be mitigated by using a tuned regularization technique, meaning that it is possible to improve the model's test performance, even using the overparameterized model where the number of parameters exceeds the number of data points.
### Learning theory
Learning theory is indeed a branch of machine learning that focuses on studying the assumptions, principles, and limitations of learning algorithms. It provides a framework for analyzing the performance of these algorithms and establishing mathematical foundations. Learning theory helps in comparing and evaluating different machine learning algorithms and guides the development of new ones. It aims to bridge the gap between empirical observations and rigorous mathematical principles to deepen the understanding of the learning process.

The performance of a machine learning (ML) algorithm can be measured by its `training error` (how well it performs on the training data) and `generalization error` (how well it performs on unseen data). Alongside this, there is a `bias error` that represents the inherent limitations of an ML algorithm in capturing the underlying structure of the data. To better understand these aspects, several important questions arise: How can we quantify the tradeoff between bias and variance? How can we assess an algorithm's performance on unseen data? And what conditions ensure that an algorithm works well?

To address these questions, we can rely on mathematical tools such as the `union bound` and `Hoeffding inequality`. The union bound helps us examine the relationship between training and generalization error. It suggests that, on average, the training error closely corresponds to the generalization error when an algorithm is trained on different datasets. On the other hand, the Hoeffding inequality allows us to investigate how the size of the training data influences the connection between training and generalization error. In simpler terms, it helps determine the minimum amount of training data needed to ensure that the training error reflects the algorithm's performance on unseen data.