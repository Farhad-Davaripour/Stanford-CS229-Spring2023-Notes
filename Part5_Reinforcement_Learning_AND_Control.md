# Part 5: Reinforcement Learning and Control
Reinforcement learning (RL) is a type of machine learning which operates in an environment where direct supervision isn't possible. The `learning agent` interacts with its environment and receives rewards or penalties. The goal is to learn a strategy that maximizes these rewards over time, learning from its interactions. Furthermore, the problem is mathematically framed using `Markov Decision Processes` (MDPs), which capture the dynamics of the environment, the possible states, actions, and the associated rewards. 

The MDO incudes stations, actions, `state transition probability`, `discount factor`, and `reward function`. The flow starts by having an initial state which changes by taking an action based on state transition probability and then the reward is calculated based on state transition. The payoff is a combination of reward due to action and state transition and the discount factor which aims to amplify the important of immediate reward compared to long term reward.

The actions are generated by a `policy function` which maps state to action based on the action that provides the highest expected sum of discounted reward. In order to find the optimal policy, a value function is defined (as described by the `Bellman equations`) which determines the policy that yields the highest expected sum of discounted rewards. . The optimal policy is the one that maximizes the expected payoff for all states regardless of the initial state.